{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import Adam\n",
    "from keras.constraints import unitnorm\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!\n<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "def get_idx_from_sent(sent, word_idx_map, max_len=51):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    x = np.zeros(shape=max_len + 1, dtype=np.int32) # sentence + label\n",
    "    for i in range(len(sent)):\n",
    "        word = sent[i]\n",
    "        if word in word_idx_map:\n",
    "            x[i] = word_idx_map[word]\n",
    "    \n",
    "    return x\n",
    "\n",
    "def make_idx_data(reviews, word_idx_map, max_len=51):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train, val, test = [], [], []\n",
    "    for rev in reviews:\n",
    "        sent = get_idx_from_sent(rev['review_text'], word_idx_map, max_len)\n",
    "        sent[-1] = rev['label']\n",
    "        if rev['split'] == 1:\n",
    "            train.append(sent)\n",
    "        elif rev['split'] == 0:\n",
    "            val.append(sent)\n",
    "        else:\n",
    "            test.append(sent)\n",
    "    \n",
    "    train = np.array(train, dtype=np.int)\n",
    "    val = np.array(val, dtype=np.int)\n",
    "    test = np.array(test, dtype=np.int)\n",
    "    return [train, val, test]\n",
    "\n",
    "\n",
    "print('Loading data...')\n",
    "with open('imdb_train_val_test_data.pkl', 'rb') as pkl_file:\n",
    "    data = pickle.load(pkl_file)\n",
    "\n",
    "reviews, W, word_idx_map, vocab = data[0], data[1], data[2], data[3]\n",
    "pkl_file.close()\n",
    "print(\"data loaded!\")\n",
    "print(type(reviews))\n",
    "\n",
    "datasets = make_idx_data(reviews, word_idx_map, max_len=1443)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape = (20027, 1443)\ntrain_Y.shape = (20027, 2)\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "num_train = datasets[0].shape[0]\n",
    "conv_input_width = W.shape[1] # word2vec length\n",
    "conv_input_height = int(datasets[0].shape[1]-1) # max sentence length\n",
    "\n",
    "train_X = np.zeros(shape=(num_train, conv_input_height), dtype=np.int32)\n",
    "train_Y = np.zeros(shape=(num_train, 2), dtype=np.int32)\n",
    "for i in range(num_train):\n",
    "    for j in range(conv_input_height):\n",
    "        train_X[i, j] = datasets[0][i, j]\n",
    "    \n",
    "    train_Y[i, datasets[0][i, -1]] = 1\n",
    "\n",
    "print('train_X.shape = {}'.format(train_X.shape))\n",
    "print('train_Y.shape = {}'.format(train_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_X.shape = (4973, 1443)\nval_Y.shape = (4973, 2)\n"
     ]
    }
   ],
   "source": [
    "# Val data\n",
    "num_val = datasets[1].shape[0]\n",
    "val_X = np.zeros(shape=(num_val, conv_input_height), dtype=np.int32)\n",
    "val_Y = np.zeros(shape=(num_val, 2), dtype=np.int32)\n",
    "for i in range(num_val):\n",
    "    for j in range(conv_input_height):\n",
    "        val_X[i, j] = datasets[1][i, j]\n",
    "    \n",
    "    val_Y[i, datasets[1][i, -1]] = 1\n",
    "\n",
    "print('val_X.shape = {}'.format(val_X.shape))\n",
    "print('val_Y.shape = {}'.format(val_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\nLayer (type)                     Output Shape          Param #     Connected to                     \n====================================================================================================\ninput_5 (InputLayer)             (None, 1443)          0                                            \n____________________________________________________________________________________________________\nembedding_5 (Embedding)          (None, 1443, 300)     47948700    input_5[0][0]                    \n____________________________________________________________________________________________________\ndropout_6 (Dropout)              (None, 1443, 300)     0           embedding_5[0][0]                \n____________________________________________________________________________________________________\ngru_7 (GRU)                      (None, 128)           164736      dropout_6[0][0]                  \n____________________________________________________________________________________________________\ngru_8 (GRU)                      (None, 128)           164736      dropout_6[0][0]                  \n____________________________________________________________________________________________________\nmerge_4 (Merge)                  (None, 256)           0           gru_7[0][0]                      \n                                                                   gru_8[0][0]                      \n____________________________________________________________________________________________________\ndropout_7 (Dropout)              (None, 256)           0           merge_4[0][0]                    \n____________________________________________________________________________________________________\ndense_3 (Dense)                  (None, 2)             514         dropout_7[0][0]                  \n____________________________________________________________________________________________________\nactivation_2 (Activation)        (None, 2)             0           dense_3[0][0]                    \n====================================================================================================\nTotal params: 48,278,686\nTrainable params: 48,278,686\nNon-trainable params: 0\n____________________________________________________________________________________________________\nNone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n  \nC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n  name=name)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, merge\n",
    "from keras.models import Model\n",
    "num_filters = 128\n",
    "kernel_size = 3\n",
    "\n",
    "input = Input(shape=(conv_input_height,), dtype='int32')\n",
    "embedded = Embedding(input_dim=W.shape[0], output_dim=W.shape[1], input_length=conv_input_height,\n",
    "                     weights=[W])(input)\n",
    "embedded = Dropout(0.5)(embedded)\n",
    "\n",
    "forwards = GRU(units=128)(embedded)\n",
    "backwards = GRU(units=128, go_backwards=True)(embedded)\n",
    "\n",
    "output = merge([forwards, backwards], mode='concat', concat_axis=1)\n",
    "# output = Flatten()(output)\n",
    "output = Dropout(0.5)(output)\n",
    "output = Dense(2, kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001))(output)\n",
    "output = Activation('softmax')(output)\n",
    "\n",
    "model = Model(input, output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "val_acc = []\n",
    "val_auc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_1 to have shape (None, 1) but got array with shape (20027, 2)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-25ec6d6d884d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvacc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_Y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1522\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1523\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1383\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1384\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    142\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m                             str(array.shape))\n\u001b[0m\u001b[0;32m    145\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_1 to have shape (None, 1) but got array with shape (20027, 2)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "for i in range(num_epoch):\n",
    "    model.fit(train_X, train_Y, batch_size=256, epochs=1, verbose=1)\n",
    "    output = model.predict(val_X, batch_size=256, verbose=1)\n",
    "    \n",
    "    vacc = np.max([np.sum((output[:,1]>t)==(val_Y[:,1]>0.5)) * 1.0 / len(output) for t in np.arange(0.0, 1.0, 0.01)])\n",
    "    vauc = roc_auc_score(val_Y, output)\n",
    "    val_acc.append(vacc)\n",
    "    val_auc.append(vauc)\n",
    "    print('Epoch {}: validation accuracy = {:.3%}, validation AUC = {:.3%}'.format(epoch, vacc, vauc))\n",
    "    epoch += 1\n",
    "\n",
    "print('{} epochs passed'.format(epoch))\n",
    "print('Accuracy on validation dataset:')\n",
    "print(val_acc)\n",
    "print('AUC on validation dataset:')\n",
    "print(val_acc)\n",
    "\n",
    "model.save_weights('c_lstm_3epochs.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
